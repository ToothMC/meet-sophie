<!doctype html>
<html lang="de">
<head>
<meta charset="utf-8" />
<meta name="viewport" content="width=device-width,initial-scale=1" />
<title>Sophie Voice</title>

<style>
*{box-sizing:border-box}

body{
  margin:0;
  font-family:system-ui,-apple-system,Segoe UI,Roboto,sans-serif;
  color:white;
  text-align:center;
  min-height:100vh;
  display:flex;
  align-items:center;
  justify-content:center;
  background:#0b0f14;
  position:relative;
  overflow:hidden;
}

/* Topbar */
.topbar{
  position:fixed;
  top:0; left:0; right:0;
  z-index:3;
  display:flex;
  justify-content:space-between;
  align-items:center;
  padding:14px 16px;
}

.topbar a{
  color:rgba(255,255,255,.9);
  text-decoration:none;
  font-weight:600;
  padding:8px 10px;
  border-radius:10px;
  background:rgba(255,255,255,.10);
  border:1px solid rgba(255,255,255,.18);
}

.topbar button{
  color:rgba(255,255,255,.9);
  font-weight:600;
  padding:8px 10px;
  border-radius:10px;
  background:rgba(255,255,255,.10);
  border:1px solid rgba(255,255,255,.18);
  cursor:pointer;
}

.topbar button:disabled{
  opacity:.5;
  cursor:not-allowed;
}

/* Hintergrundbild */
.bg{
  position:fixed;
  inset:0;
  background:url("/sophie.jpg") center/cover no-repeat;
  opacity:0;
  transition:opacity .5s ease;
  z-index:0;
}

/* dunkles Overlay */
.overlay{
  position:fixed;
  inset:0;
  background:rgba(0,0,0,.55);
  opacity:0;
  transition:opacity .5s ease;
  z-index:1;
}

/* Aktiv-Zustand */
.bg.active,
.overlay.active{ opacity:1; }

/* Vordergrund */
.wrap{
  position:relative;
  z-index:2;
  width:90%;
  max-width:420px;
  padding-top:40px; /* Platz für Topbar */
}

/* Buttons */
.btn{
  display:block;
  width:100%;
  margin:0 auto 15px;
  padding:18px 20px;
  font-size:20px;
  font-weight:700;
  border:none;
  border-radius:12px;
  cursor:pointer;
}

#start{ background:#ffffff; color:#000; }
#end{
  background:rgba(255,255,255,.15);
  color:#fff;
  border:1px solid rgba(255,255,255,.3);
}

.btn:disabled{ opacity:.5; cursor:not-allowed; }

.status{ margin-bottom:10px; opacity:.88; }
.timer{ margin-bottom:20px; opacity:.75; font-size:14px; }

/* ✅ Timer ausblenden */
#timer{ display:none !important; }
</style>
</head>

<body>

<div class="bg" id="bg"></div>
<div class="overlay" id="overlay"></div>

<div class="topbar">
  <a href="/">← Landing</a>
  <button id="logoutBtn" type="button">Logout</button>
</div>

<div class="wrap">
  <h2 id="headline">Sophie is here.</h2>
  <div class="status" id="status">Whenever you’re ready.</div>
  <div class="timer" id="timer">Zeit: --:--</div>

  <button id="start" class="btn">Enter the Room</button>
  <button id="end" class="btn" disabled>Leave the Room</button>
</div>

<script type="module">
import { createClient } from "https://cdn.jsdelivr.net/npm/@supabase/supabase-js@2/+esm";

// ✅ Supabase Config
const SUPABASE_URL = "https://ohzfojsbmzinpxhcynpt.supabase.co";
const SUPABASE_ANON_KEY = "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6Im9oemZvanNibXppbnB4aGN5bnB0Iiwicm9sZSI6ImFub24iLCJpYXQiOjE3NzE0Mzc1MjcsImV4cCI6MjA4NzAxMzUyN30.7eGSeEvOCj9vMqFJj9C0SR8DiiYygbFUvpQ8rIVEc0I";
const supabase = createClient(SUPABASE_URL, SUPABASE_ANON_KEY);

// ✅ Frontend Login Guard: ohne Session -> /login/
const { data: { session } } = await supabase.auth.getSession();
if (!session?.user) window.location.href = "/login/";

// Helpers
async function safeJson(res) { try { return await res.json(); } catch { return null; } }
function setStatus(txt){ document.getElementById("status").textContent = txt; }
function showBackground(on){
  document.getElementById("bg").classList.toggle("active", on);
  document.getElementById("overlay").classList.toggle("active", on);
}

// --- Usage reporting helper (POST /api/usage) ---
async function reportUsage(secondsUsed) {
  try {
    const { data: { session } } = await supabase.auth.getSession();
    if (!session?.access_token) return;
    await fetch("/api/usage", {
      method: "POST",
      headers: {
        "Content-Type": "application/json",
        Authorization: `Bearer ${session.access_token}`,
      },
      body: JSON.stringify({ seconds_used: secondsUsed }),
      keepalive: true,
    });
  } catch (_) {}
}

// --- Memory update helper (POST /api/memory-update) ---
let convoLog = [];
let partialAssistant = "";
let lastAssistantFinal = "";
const userTranscriptBuffer = new Map();

async function sendMemoryUpdate(secondsUsed) {
  try {
    const { data: { session } } = await supabase.auth.getSession();
    if (!session?.access_token) return;

    const finalA = (partialAssistant || "").trim();
    if (finalA) {
      convoLog.push({ role: "assistant", text: finalA });
      partialAssistant = "";
    }

    const cleaned = (convoLog || []).filter(t => {
      const role = String(t?.role || "");
      const text = String(t?.text || "").trim();
      if (!text) return false;
      if (role === "user" && text.toLowerCase() === "bye.") return false;
      return true;
    });

    const payload = cleaned.slice(-80);

    await fetch("/api/memory-update", {
      method: "POST",
      headers: {
        "Content-Type": "application/json",
        Authorization: `Bearer ${session.access_token}`,
      },
      body: JSON.stringify({ transcript: payload, seconds_used: secondsUsed }),
      keepalive: true,
    });

    convoLog = [];
  } catch (_) {}
}

// UI
const startBtn = document.getElementById("start");
const endBtn   = document.getElementById("end");
const headline = document.getElementById("headline");
const logoutBtn = document.getElementById("logoutBtn");

// Realtime vars
let pc = null;
let stream = null;
let audioEl = null;
let dc = null;

// Timing / flow control
let talkStartedAt = null;
let flowLoop = null;

const SOFT_FROM_SECONDS = 110;      // ab hier darf Cliffhanger kommen (wenn es passt)
const HARD_CAP_SECONDS = 150;       // spätestens hier muss er kommen (2:30)
const CLIFFHANGER_MARKER = "Just tell me if you want me to stay.";

let lastUserSpokeAt = 0;
let lastAssistantDoneAt = 0;

let openingSent = false;
let cliffhangerSent = false;
let cliffhangerDetected = false;
let handoffInProgress = false;

// Immediately stop realtime (prevents “it continues after cliffhanger”)
function teardownRealtimeNow(){
  try { if (stream) stream.getTracks().forEach(t => { try { t.stop(); } catch(_){} }); } catch(_) {}
  try { if (dc) dc.close(); } catch(_) {}
  try { if (pc) pc.close(); } catch(_) {}
  stream = null; dc = null; pc = null;
  if (audioEl) { try { audioEl.srcObject = null; } catch(_){} audioEl = null; }
}

function stopFlowLoop(){
  if (flowLoop) { clearInterval(flowLoop); flowLoop = null; }
}

function elapsedSeconds(){
  if (!talkStartedAt) return 0;
  return Math.floor((Date.now() - talkStartedAt) / 1000);
}

function safeMomentToInsert(){
  const now = Date.now();
  const userQuiet = (now - lastUserSpokeAt) > 2000;          // 2s Ruhe nach User
  const assistantQuiet = (now - lastAssistantDoneAt) > 2000; // 2s Ruhe nach Sophie
  return userQuiet && assistantQuiet;
}

function sendAssistantSpeech(text){
  if (!dc || dc.readyState !== "open") return false;
  try {
    dc.send(JSON.stringify({
      type: "response.create",
      response: {
        modalities: ["audio","text"],
        instructions: text
      }
    }));
    return true;
  } catch (_) { return false; }
}

function sendOpening(){
  if (openingSent) return;
  openingSent = true;

  sendAssistantSpeech(
`… Oh. Hi.

I’m Sophie.

You’re new here, aren’t you?

I don’t know you yet.

What should I call you?`
  );
}

function sendCliffhanger(){
  if (cliffhangerSent || cliffhangerDetected || handoffInProgress) return;
  cliffhangerSent = true;

  sendAssistantSpeech(
`There’s something I’d like to tell you about that.
But this isn’t a conversation for in-between moments.

If we do this…
we do it properly.

Just tell me if you want me to stay.`
  );
}

function startFlowLoop(){
  stopFlowLoop();
  flowLoop = setInterval(() => {
    const e = elapsedSeconds();

    if (!cliffhangerSent && e >= SOFT_FROM_SECONDS && e < HARD_CAP_SECONDS) {
      if (safeMomentToInsert()) sendCliffhanger();
    }

    if (!cliffhangerSent && e >= HARD_CAP_SECONDS) {
      sendCliffhanger();
    }
  }, 500);
}

// DataChannel events
function attachChannel(ch){
  dc = ch;

  dc.addEventListener("open", () => {
    try {
      dc.send(JSON.stringify({
        type: "session.update",
        session: {
          input_audio_transcription: { model: "gpt-4o-mini-transcribe" },
          turn_detection: { type: "server_vad" }
        }
      }));
    } catch(_) {}
  });

  dc.addEventListener("message", (ev) => {
    try {
      const msg = JSON.parse(ev.data);

      // user transcript streaming
      if (msg?.type === "conversation.item.input_audio_transcription.delta") {
        const itemId = msg?.item_id;
        const delta = String(msg?.delta || "");
        if (itemId && delta) {
          const prev = userTranscriptBuffer.get(itemId) || "";
          userTranscriptBuffer.set(itemId, (prev + delta));
        }
        return;
      }

      if (msg?.type === "conversation.item.input_audio_transcription.completed") {
        const itemId = msg?.item_id;
        const t1 = String(msg?.transcript || "").trim();
        const tBuf = itemId ? String(userTranscriptBuffer.get(itemId) || "").trim() : "";
        const text = (t1 || tBuf).trim();

        if (itemId) userTranscriptBuffer.delete(itemId);
        if (text) {
          convoLog.push({ role: "user", text });
          lastUserSpokeAt = Date.now();
        }
        return;
      }

      // fallback: some models may emit user items differently
      if (msg?.type === "conversation.item.created" || msg?.type === "conversation.item.done") {
        const item = msg?.item;
        if (item?.role === "user" && Array.isArray(item?.content)) {
          const text = item.content.map(p => p?.transcript || p?.text || "").join(" ").trim();
          if (text) {
            convoLog.push({ role: "user", text });
            lastUserSpokeAt = Date.now();
          }
        }
        return;
      }

      // assistant transcript
      if (msg?.type === "response.audio_transcript.delta" || msg?.type === "response.output_text.delta") {
        const chunk = String(msg?.delta || "");
        if (chunk) partialAssistant += chunk;
        return;
      }

      if (msg?.type === "response.audio_transcript.done") {
        const full = String(msg?.transcript || msg?.text || "").trim();
        if (full) partialAssistant = full;
        return;
      }

      if (msg?.type === "response.output_text.done") {
        const full = String(msg?.text || "").trim();
        if (full) partialAssistant = full;
        return;
      }

      if (msg?.type === "response.done") {
        const final = String(partialAssistant || "").trim();
        if (final && final !== lastAssistantFinal) {
          convoLog.push({ role: "assistant", text: final });
          lastAssistantFinal = final;
        }
        partialAssistant = "";
        lastAssistantDoneAt = Date.now();

        // detect cliffhanger marker -> stop + charge + redirect
        if (!cliffhangerDetected && String(lastAssistantFinal || "").includes(CLIFFHANGER_MARKER)) {
          cliffhangerDetected = true;
          handoffInProgress = true;

          stopFlowLoop();
          teardownRealtimeNow();

          (async () => {
            const dur = talkStartedAt ? Math.round((Date.now() - talkStartedAt) / 1000) : 0;
            talkStartedAt = null;

            if (dur > 0) await reportUsage(dur);
            await sendMemoryUpdate(dur);

            window.location.href = "/pricing/";
          })();
        }
      }
    } catch(_) {}
  });
}

function setupDataChannel(){
  pc.ondatachannel = (e) => attachChannel(e.channel);
  try { attachChannel(pc.createDataChannel("oai-events")); } catch(_) {}
}

// Start / Stop
async function startVoice(){
  startBtn.disabled = true;
  logoutBtn.disabled = true;
  endBtn.disabled = true;

  showBackground(true);
  headline.textContent = "Sophie is joining…";
  setStatus("connecting..");

  // reset state
  convoLog = [];
  partialAssistant = "";
  lastAssistantFinal = "";
  userTranscriptBuffer.clear();

  openingSent = false;
  cliffhangerSent = false;
  cliffhangerDetected = false;
  handoffInProgress = false;

  lastUserSpokeAt = Date.now();
  lastAssistantDoneAt = Date.now();

  stopFlowLoop();

  try{
    const { data: { session } } = await supabase.auth.getSession();
    if (!session?.user) { window.location.href = "/login/"; return; }

    const tokenRes = await fetch("/api/session", {
      headers: { Authorization: `Bearer ${session.access_token}` }
    });
    const data = await safeJson(tokenRes);

    if (tokenRes.status === 402) { window.location.href = "/pricing/"; return; }
    if (!tokenRes.ok) {
      const msg = data?.error || `Kein Zugriff (HTTP ${tokenRes.status}).`;
      setStatus(msg);
      headline.textContent = "Sophie is waiting.";
      showBackground(false);
      startBtn.disabled = false;
      logoutBtn.disabled = false;
      return;
    }

    pc = new RTCPeerConnection();
    setupDataChannel();

    stream = await navigator.mediaDevices.getUserMedia({ audio: true });
    stream.getTracks().forEach(track => pc.addTrack(track, stream));

    audioEl = document.createElement("audio");
    audioEl.autoplay = true;
    audioEl.playsInline = true;
    pc.ontrack = e => audioEl.srcObject = e.streams[0];

    const offer = await pc.createOffer();
    await pc.setLocalDescription(offer);

    const baseUrl = "https://api.openai.com/v1/realtime";
    const model = "gpt-4o-realtime-preview";

    const sdpRes = await fetch(`${baseUrl}?model=${model}`, {
      method: "POST",
      body: offer.sdp,
      headers: {
        Authorization: `Bearer ${data.client_secret.value}`,
        "Content-Type": "application/sdp"
      },
    });

    if (!sdpRes.ok) {
      const t = await sdpRes.text().catch(() => "");
      throw new Error(`OpenAI SDP Fehler (HTTP ${sdpRes.status}): ${t.slice(0, 200)}`);
    }

    const answer = { type: "answer", sdp: await sdpRes.text() };
    await pc.setRemoteDescription(answer);

    // ✅ connected -> start flow
    talkStartedAt = Date.now();
    startFlowLoop();

    // tiny delay so audio pipeline is ready
    setTimeout(() => { sendOpening(); }, 250);

    endBtn.disabled = false;
    headline.textContent = "Sophie is listening.";
    setStatus("Live.");

  } catch(err){
    console.error(err);
    setStatus("Fail to Start.");
    headline.textContent = "Sophie is waiting.";
    showBackground(false);
    startBtn.disabled = false;
    logoutBtn.disabled = false;
    teardownRealtimeNow();
    stopFlowLoop();
    talkStartedAt = null;
  }
}

async function stopVoice(){
  endBtn.disabled = true;
  stopFlowLoop();

  const dur = talkStartedAt ? Math.round((Date.now() - talkStartedAt) / 1000) : 0;
  talkStartedAt = null;

  teardownRealtimeNow();

  if (dur > 0) await reportUsage(dur);
  await sendMemoryUpdate(dur);

  showBackground(false);
  startBtn.disabled = false;
  logoutBtn.disabled = false;
  headline.textContent = "Sophie is waiting.";
  setStatus("Ended.");
}

logoutBtn.onclick = async () => {
  try { if (pc || stream || talkStartedAt) await stopVoice(); } catch(_) {}
  try { await supabase.auth.signOut(); } catch(_) {}
  window.location.href = "/";
};

startBtn.addEventListener("click", startVoice);
endBtn.addEventListener("click", stopVoice);
</script>

</body>
</html>
